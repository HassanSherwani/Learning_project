{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patent Assignment Daily\n",
    "Contains daily patent assignment text for 10/18/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = pd.read_csv('patent_assignment.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last-update-date</th>\n",
       "      <th>patent-assignees</th>\n",
       "      <th>patent-assignors</th>\n",
       "      <th>patent-countries</th>\n",
       "      <th>patent-dates</th>\n",
       "      <th>patent-kinds</th>\n",
       "      <th>patent-numbers</th>\n",
       "      <th>recorded-date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20161018</td>\n",
       "      <td>FASTCASE</td>\n",
       "      <td>WALTERS, EDWARD J. III|ROSENTHAL, PHILIP J.</td>\n",
       "      <td>US|US</td>\n",
       "      <td>20001108|20161018</td>\n",
       "      <td>X0|B1</td>\n",
       "      <td>09707911|9471672</td>\n",
       "      <td>20010320</td>\n",
       "      <td>Relevance sorting for database searches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20161018</td>\n",
       "      <td>ANABASIS SRL</td>\n",
       "      <td>LAMBIASE, ALESSANDRO</td>\n",
       "      <td>US|US</td>\n",
       "      <td>20010726|20161018</td>\n",
       "      <td>X0|B1</td>\n",
       "      <td>09890088|9468665</td>\n",
       "      <td>20010720</td>\n",
       "      <td>METHOD OF TREATING INTRAOCCULAR TISSUE PATHOLO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20161018</td>\n",
       "      <td>QUALCOMM INCORPORATED</td>\n",
       "      <td>WALTON, J. RODNEY|KETCHUM, JOHN W.</td>\n",
       "      <td>US|US|US</td>\n",
       "      <td>20031201|20050602|20161018</td>\n",
       "      <td>X0|A1|B2</td>\n",
       "      <td>10725904|20050120097|9473269</td>\n",
       "      <td>20031201</td>\n",
       "      <td>METHOD AND APPARATUS FOR PROVIDING AN EFFICIEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20161018</td>\n",
       "      <td>INTERNATIONAL BUSINESS MACHINES CORPORATION</td>\n",
       "      <td>MORARIU, JANIS A.|STAPEL, STEVEN W.|STRAACH, J...</td>\n",
       "      <td>US|US|US</td>\n",
       "      <td>20040622|20051222|20161018</td>\n",
       "      <td>X0|A1|B2</td>\n",
       "      <td>10873346|20050282136|9472114</td>\n",
       "      <td>20040903</td>\n",
       "      <td>COMPUTER-IMPLEMENTED METHOD, SYSTEM AND PROGRA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20161018</td>\n",
       "      <td>INTERNATIONAL BUSINESS MACHINES CORPORATION</td>\n",
       "      <td>LI, XIN|ROBERTS, GREGORY WAYNE</td>\n",
       "      <td>US|US|US</td>\n",
       "      <td>20041019|20060420|20161018</td>\n",
       "      <td>X0|A1|B2</td>\n",
       "      <td>10967958|20060085754|9471332</td>\n",
       "      <td>20050208</td>\n",
       "      <td>Selecting graphical component types at runtime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   last-update-date                             patent-assignees  \\\n",
       "0          20161018                                     FASTCASE   \n",
       "1          20161018                                 ANABASIS SRL   \n",
       "2          20161018                        QUALCOMM INCORPORATED   \n",
       "3          20161018  INTERNATIONAL BUSINESS MACHINES CORPORATION   \n",
       "4          20161018  INTERNATIONAL BUSINESS MACHINES CORPORATION   \n",
       "\n",
       "                                    patent-assignors patent-countries  \\\n",
       "0        WALTERS, EDWARD J. III|ROSENTHAL, PHILIP J.            US|US   \n",
       "1                               LAMBIASE, ALESSANDRO            US|US   \n",
       "2                 WALTON, J. RODNEY|KETCHUM, JOHN W.         US|US|US   \n",
       "3  MORARIU, JANIS A.|STAPEL, STEVEN W.|STRAACH, J...         US|US|US   \n",
       "4                     LI, XIN|ROBERTS, GREGORY WAYNE         US|US|US   \n",
       "\n",
       "                 patent-dates patent-kinds                patent-numbers  \\\n",
       "0           20001108|20161018        X0|B1              09707911|9471672   \n",
       "1           20010726|20161018        X0|B1              09890088|9468665   \n",
       "2  20031201|20050602|20161018     X0|A1|B2  10725904|20050120097|9473269   \n",
       "3  20040622|20051222|20161018     X0|A1|B2  10873346|20050282136|9472114   \n",
       "4  20041019|20060420|20161018     X0|A1|B2  10967958|20060085754|9471332   \n",
       "\n",
       "   recorded-date                                              title  \n",
       "0       20010320            Relevance sorting for database searches  \n",
       "1       20010720  METHOD OF TREATING INTRAOCCULAR TISSUE PATHOLO...  \n",
       "2       20031201  METHOD AND APPARATUS FOR PROVIDING AN EFFICIEN...  \n",
       "3       20040903  COMPUTER-IMPLEMENTED METHOD, SYSTEM AND PROGRA...  \n",
       "4       20050208     Selecting graphical component types at runtime  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_in_data=assignments['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(set(titles_in_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patent data has chars 7530\n",
      "Patent data has unique chars 6441\n"
     ]
    }
   ],
   "source": [
    "data_size, vocab_size = len(titles_in_data), len(chars)\n",
    "print (\"Patent data has chars\", data_size)\n",
    "print (\"Patent data has unique chars\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "import nltk\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we have to do is **tokenize** our words. A naive way to do this would be to split our string based on spaces (e.g. str.split(\" \")), which is sometimes OK but has many edge cases (alternative punctuation marks like —, for example) and will fail to work as expected for larger problems.\n",
    "\n",
    "nltk comes with a built-in word tokenizer that we can take advantage of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = assignments['title']\n",
    "title_tokens = [nltk.word_tokenize(title) for title in\\\n",
    "                    np.concatenate(titles.map(str).map(str.title).map(lambda s: s.split(\"|\")))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tokens = [title for title in title_tokens if len(title_tokens) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370460"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Relevance', 'Sorting', 'For', 'Database', 'Searches'],\n",
       " ['Method',\n",
       "  'Of',\n",
       "  'Treating',\n",
       "  'Intraoccular',\n",
       "  'Tissue',\n",
       "  'Pathologies',\n",
       "  'With',\n",
       "  'Nerve',\n",
       "  'Growth',\n",
       "  'Factor',\n",
       "  '.'],\n",
       " ['Method',\n",
       "  'And',\n",
       "  'Apparatus',\n",
       "  'For',\n",
       "  'Providing',\n",
       "  'An',\n",
       "  'Efficient',\n",
       "  'Control',\n",
       "  'Channel',\n",
       "  'Structure',\n",
       "  'In',\n",
       "  'A',\n",
       "  'Wireless',\n",
       "  'Communication',\n",
       "  'System']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tokens[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Method', 'And', 'Apparatus', 'For', 'Providing', 'An', 'Efficient', 'Control', 'Channel', 'Structure', 'In', 'A', 'Wireless', 'Communication', 'System']\n"
     ]
    }
   ],
   "source": [
    "print(title_tokens[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will stem our words. Stemming is a procedure in natural language processing where we chop off everything except for the root of a word. So for example, the words go, going, and gone will all map to the same root—go.\n",
    "\n",
    "This is a good thing to do, particularly given the small size of our documents, because it increases the accuracy of classifications—more things end up being the same.\n",
    "\n",
    "nltk comes with several stemmers installed, we'll use the PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "titles_stemmed = [[stemmer.stem(token) for token in tokens] for tokens in title_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['relev', 'sort', 'for', 'databas', 'search'],\n",
       " ['method',\n",
       "  'Of',\n",
       "  'treat',\n",
       "  'intraoccular',\n",
       "  'tissu',\n",
       "  'patholog',\n",
       "  'with',\n",
       "  'nerv',\n",
       "  'growth',\n",
       "  'factor',\n",
       "  '.'],\n",
       " ['method',\n",
       "  'and',\n",
       "  'apparatu',\n",
       "  'for',\n",
       "  'provid',\n",
       "  'An',\n",
       "  'effici',\n",
       "  'control',\n",
       "  'channel',\n",
       "  'structur',\n",
       "  'In',\n",
       "  'A',\n",
       "  'wireless',\n",
       "  'commun',\n",
       "  'system']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_stemmed[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['method', 'and', 'apparatu', 'for', 'provid', 'An', 'effici', 'control', 'channel', 'structur', 'In', 'A', 'wireless', 'commun', 'system']\n"
     ]
    }
   ],
   "source": [
    "print(titles_stemmed[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we examine a list of words, however, we see that the most common English-language words dominate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and                             170856\n",
      "for                             145224\n",
      "method                          137910\n",
      "A                               101633\n",
      "Of                               91017\n",
      "system                           75843\n",
      "devic                            65015\n",
      "with                             46433\n",
      "In                               39461\n",
      ",                                37235\n",
      "apparatu                         31147\n",
      "circuit                          29046\n",
      "memori                           28675\n",
      "semiconductor                    26290\n",
      "use                              24697\n",
      "To                               23959\n",
      "data                             22710\n",
      "An                               22235\n",
      "control                          20957\n",
      "the                              20244\n",
      "have                             17662\n",
      "integr                           16994\n",
      "process                          16233\n",
      "structur                         16052\n",
      "network                          14185\n",
      "form                             14012\n",
      "On                               12411\n",
      "commun                           12408\n",
      "power                            11927\n",
      "same                             10940\n",
      "                                 ...  \n",
      "component                            1\n",
      "semiconductor/oxid                   1\n",
      "gabric                               1\n",
      "caller-provid                        1\n",
      "svc-l2                               1\n",
      "connection-                          1\n",
      "ssp                                  1\n",
      "styrene-contain                      1\n",
      "andmotor                             1\n",
      "aminoalkyl                           1\n",
      "2-heteroaryl-6-phenylimidazo         1\n",
      "dual-network                         1\n",
      "tech-librari                         1\n",
      "nqo1                                 1\n",
      "base-solubility-enhanc               1\n",
      "camp-on                              1\n",
      "pretension                           1\n",
      "end-of-test                          1\n",
      "pull-tab                             1\n",
      "muti-touch                           1\n",
      "full-and-partial-scan                1\n",
      "top-emiss                            1\n",
      "anti-gp73                            1\n",
      "intercal                             1\n",
      "zero-catch                           1\n",
      "demi-syl                             1\n",
      "keypress                             1\n",
      "quick-load                           1\n",
      "bithiophen                           1\n",
      "position-mark                        1\n",
      "Length: 32335, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(np.concatenate(titles_stemmed)).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These words carry no meaning and aren't very interesting.For example, we can see \",\" has occurance of  37235. <br>\n",
    "\n",
    "They're known as **stopwords** in NLP, and we're going to once again use  nltk builtins to remove them from consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = set([word.title() for word in stopwords.words(\"english\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_title_words = [[word for word in title if word not in english_stopwords] for title in titles_stemmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['relev', 'sort', 'for', 'databas', 'search'],\n",
       " ['method',\n",
       "  'treat',\n",
       "  'intraoccular',\n",
       "  'tissu',\n",
       "  'patholog',\n",
       "  'with',\n",
       "  'nerv',\n",
       "  'growth',\n",
       "  'factor',\n",
       "  '.'],\n",
       " ['method',\n",
       "  'and',\n",
       "  'apparatu',\n",
       "  'for',\n",
       "  'provid',\n",
       "  'effici',\n",
       "  'control',\n",
       "  'channel',\n",
       "  'structur',\n",
       "  'wireless',\n",
       "  'commun',\n",
       "  'system']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_title_words[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['method', 'and', 'apparatu', 'for', 'provid', 'effici', 'control', 'channel', 'structur', 'wireless', 'commun', 'system']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed_title_words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = pd.Series(np.concatenate(stemmed_title_words)).value_counts()\n",
    "singular_words = set(word_counts[pd.Series(np.concatenate(stemmed_title_words)).value_counts() == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_title_common_words = [[word for word in title if word not in singular_words] for title in stemmed_title_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['relev', 'sort', 'for', 'databas', 'search'],\n",
       " ['method',\n",
       "  'treat',\n",
       "  'intraoccular',\n",
       "  'tissu',\n",
       "  'patholog',\n",
       "  'with',\n",
       "  'nerv',\n",
       "  'growth',\n",
       "  'factor',\n",
       "  '.'],\n",
       " ['method',\n",
       "  'and',\n",
       "  'apparatu',\n",
       "  'for',\n",
       "  'provid',\n",
       "  'effici',\n",
       "  'control',\n",
       "  'channel',\n",
       "  'structur',\n",
       "  'wireless',\n",
       "  'commun',\n",
       "  'system']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_title_common_words[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['method', 'and', 'apparatu', 'for', 'provid', 'effici', 'control', 'channel', 'structur', 'wireless', 'commun', 'system']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed_title_common_words[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's consider the opposite problem: words that occur to infrequently to be useful. Words that only ever appear once, for example, don't carry any information. Remember, we're going to split all of our patent titles into some small number of classes; just as in any other dataset, a data point which is only populated once isn't interesting, and can be safely dropped.\n",
    "\n",
    "In fact, we could probably drop a lot of words from consideration, not just ones appearing once but ones appearing tens or even hundreds of times. This would speed up our algorithms and won't significantly impact our results.\n",
    "\n",
    "After a certain point words do start to matter, however; figuring out where that point is is up to you.\n",
    "\n",
    "In our case we'll just be lazy and cut off at words that appear only once, and leave words appearing twice or more intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty_indices = [i for i in range(len(stemmed_title_common_words)) if len(stemmed_title_common_words[i]) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5003"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_empty_indices[5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that discarding words from our set has resulted in a handful of empty titles. Apparently a few patents have nothing but unique words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_title_common_words_nonnull = np.asarray(stemmed_title_common_words)[non_empty_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiable_titles = np.asarray(title_tokens)[non_empty_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['Relevance', 'Sorting', 'For', 'Database', 'Searches']),\n",
       "       list(['Method', 'Of', 'Treating', 'Intraoccular', 'Tissue', 'Pathologies', 'With', 'Nerve', 'Growth', 'Factor', '.']),\n",
       "       list(['Method', 'And', 'Apparatus', 'For', 'Providing', 'An', 'Efficient', 'Control', 'Channel', 'Structure', 'In', 'A', 'Wireless', 'Communication', 'System']),\n",
       "       list(['Computer-Implemented', 'Method', ',', 'System', 'And', 'Program', 'Product', 'For', 'Providing', 'An', 'Educational', 'Program']),\n",
       "       list(['Selecting', 'Graphical', 'Component', 'Types', 'At', 'Runtime'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiable_titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our titles adequately processed, now we switch over to gensim. The first thing we have to do is build a dictionary of words, which associates each word [stem] with a particular index number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(stemmed_title_common_words_nonnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'databas': 0, 'for': 1, 'relev': 2, 'search': 3, 'sort': 4, '.': 5, 'factor': 6, 'growth': 7, 'intraoccular': 8, 'method': 9, 'nerv': 10, 'patholog': 11, 'tissu': 12, 'treat': 13, 'with': 14, 'and': 15, 'apparatu': 16, 'channel': 17, 'commun': 18, 'control': 19, 'effici': 20, 'provid': 21, 'structur': 22, 'system': 23, 'wireless': 24, ',': 25, 'computer-impl': 26, 'educ': 27, 'product': 28, 'program': 29, 'compon': 30, 'graphic': 31, 'runtim': 32, 'select': 33, 'type': 34, 'aggreg': 35, 'chromatographi': 36, 'high': 37, 'hydroxyapatit': 38, 'molecular': 39, 'remov': 40, 'use': 41, 'weight': 42, 'aid': 43, 'differ': 44, 'further': 45, 'protocol': 46, 'station': 47, 'the': 48, 'transpond': 49, 'convert': 50, 'input': 51, 'languag': 52, 'output': 53, 'phonet': 54, 'written': 55, 'dataset': 56, 'from': 57, 'link': 58, 'methodolog': 59, 'multi-mod': 60, 'pattern': 61, 'charact': 62, 'digit': 63, 'media': 64, 'person': 65, 'replac': 66, 'airway': 67, 'detect': 68, 'instabl': 69, 'align': 70\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(dictionary.token2id)[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are we doing this? Because shortly we're going to throw our corpus into a tf-idf algorithm. TF-IDF is an algorithm in information retrieval which converts a list of word \"vectors\" to a scaled Euclidian normal vector. It turns a count of the number of each word in our document into a unit vector in N-dimensional space, where N is, believe it or not, the number of individual words that we have in our dictionary (above).\n",
    "\n",
    "That means that, in this case, we have a \"dataset\" matrix with hundreds of thousands of columns in it!\n",
    "\n",
    "The beauty of TD-IDF is that it scales the words according to how frequent or rare they are. Words that appear a lot in your text but also appear a lot in the rest of the corpus are weighed less heavily than words that appear a lot in your text but more rarely outside of it.\n",
    "\n",
    "Thus we first use gensim to convert our words to word incidence vectors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in stemmed_title_common_words_nonnull]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['relev', 'sort', 'for', 'databas', 'search'],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_title_common_words_nonnull[0], corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['method', 'and', 'apparatu', 'for', 'provid', 'effici', 'control', 'channel', 'structur', 'wireless', 'commun', 'system'] [(1, 1), (9, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(stemmed_title_common_words_nonnull[2], corpus[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['passeng', 'transport', 'system', 'and', 'method', 'for', 'obtain', 'ticket', 'such', 'system'] [(1, 1), (9, 1), (15, 1), (23, 2), (300, 1), (325, 1), (326, 1), (327, 1), (328, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(stemmed_title_common_words_nonnull[100], corpus[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..then run TfidfModel from gensim on them to turn them into our word vectors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that gensim doesn't follow the scikit access pattern, if you are familiar with it. It instead (1) defers computations on individual entries until necessary and (2) provides access to data using bracket indexing notation ([]).\n",
    "\n",
    "By contrast, scikit will run everything immediately by default, provides results using a .values_ attribute, and seperates model initialization from runtime (the latter doesn't occur until you fit() your model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['relev', 'sort', 'for', 'databas', 'search'],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)],\n",
       " [(0, 0.4377475295381456),\n",
       "  (1, 0.07562061510033051),\n",
       "  (2, 0.5469009211535774),\n",
       "  (3, 0.36992777626242423),\n",
       "  (4, 0.6055670447985132)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_title_common_words_nonnull[0], corpus[0], tfidf[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['method', 'and', 'apparatu', 'for', 'provid', 'effici', 'control', 'channel', 'structur', 'wireless', 'commun', 'system'] [(1, 1), (9, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1)] [(1, 0.08840592502566112), (9, 0.08992064121432716), (15, 0.07858769583335751), (16, 0.22360915542920912), (17, 0.42309521007730033), (18, 0.3118124008719702), (19, 0.26099879446104235), (20, 0.44892517091974105), (21, 0.3559213131631317), (22, 0.2847423513065349), (23, 0.14769708350864824), (24, 0.3904590429022807)]\n"
     ]
    }
   ],
   "source": [
    "print(stemmed_title_common_words_nonnull[2], corpus[2], tfidf[corpus[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our words suitibly datified, we can now move on to fitting a model. Since our words are now, effectively, a very large dataset, it's possible to use any general purpose classifier to fit it.  For example,We could use a scipy KMeans clustering algorithm to arrive at its topics.\n",
    "\n",
    "We'll instead use a model specifically adapted to natural language processing from the gensim built-ins, **LsiModel**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LsiModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus]\n",
    "lsi = LsiModel(tfidf[corpus], id2word=dictionary, num_topics=10)\n",
    "corpus_lsi = lsi[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a printout of what words are important to our various topics. Notice that certain extremely common words, like semiconductor, appear in different positions in multiple classifiers. Also, note that this display is cut off at a certain number of displayed words; in reality the model considers far more than these (you can specify how many to display here, however, using the num_words parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.381*\"devic\" + 0.350*\"semiconductor\" + 0.299*\"method\" + 0.281*\"and\" + 0.229*\"for\" + 0.228*\"system\" + 0.194*\",\" + 0.188*\"memori\" + 0.183*\"circuit\" + 0.153*\"apparatu\"'),\n",
       " (1,\n",
       "  '-0.603*\"semiconductor\" + -0.353*\"devic\" + 0.327*\"system\" + 0.197*\"apparatu\" + 0.171*\"for\" + 0.167*\"data\" + 0.153*\"and\" + 0.152*\",\" + -0.146*\"manufactur\" + -0.132*\"form\"'),\n",
       " (2,\n",
       "  '-0.719*\"circuit\" + -0.502*\"integr\" + 0.161*\"system\" + 0.121*\"data\" + 0.114*\"semiconductor\" + 0.112*\"devic\" + -0.112*\"packag\" + -0.100*\"voltag\" + 0.100*\"commun\" + 0.096*\"network\"'),\n",
       " (3,\n",
       "  '0.673*\"memori\" + -0.342*\"commun\" + 0.282*\"cell\" + -0.196*\"handl\" + -0.172*\"semiconductor\" + -0.164*\"inform\" + 0.141*\"non-volatil\" + -0.124*\"wireless\" + -0.114*\"devic\" + 0.112*\"form\"'),\n",
       " (4,\n",
       "  '-0.563*\",\" + -0.301*\"imag\" + -0.259*\"apparatu\" + 0.237*\"handl\" + 0.235*\"system\" + 0.210*\"manag\" + -0.188*\"display\" + 0.182*\"power\" + 0.163*\"network\" + 0.157*\"inform\"'),\n",
       " (5,\n",
       "  '-0.575*\"fiber\" + -0.541*\"optic\" + -0.275*\"cabl\" + -0.273*\"connector\" + 0.181*\"handl\" + 0.178*\"inform\" + 0.136*\",\" + -0.105*\"with\" + -0.103*\"modul\" + -0.092*\"assembl\"'),\n",
       " (6,\n",
       "  '-0.509*\"handl\" + -0.418*\"inform\" + 0.364*\"commun\" + -0.246*\"game\" + 0.243*\"network\" + -0.178*\"system\" + 0.171*\"data\" + 0.154*\"wireless\" + -0.143*\"display\" + -0.135*\",\"'),\n",
       " (7,\n",
       "  '-0.831*\"game\" + -0.331*\"wager\" + -0.234*\"machin\" + 0.206*\"handl\" + 0.168*\"inform\" + -0.090*\"with\" + -0.083*\"commun\" + -0.066*\"featur\" + -0.058*\"network\" + -0.055*\"control\"'),\n",
       " (8,\n",
       "  '-0.497*\"light\" + -0.365*\"display\" + -0.280*\"organ\" + -0.270*\"emit\" + 0.262*\",\" + 0.233*\"form\" + -0.205*\"devic\" + 0.166*\"semiconductor\" + -0.147*\"same\" + -0.146*\"the\"'),\n",
       " (9,\n",
       "  '0.450*\",\" + 0.329*\"network\" + -0.320*\"imag\" + -0.266*\"apparatu\" + -0.231*\"power\" + 0.215*\"memori\" + 0.185*\"commun\" + 0.151*\"devic\" + -0.146*\"form\" + -0.130*\"structur\"')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the scoring outputs for the first five documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.025505540264359014), (1, 0.027408435972474353), (2, 0.014314312172872854), (3, 0.0009359003513390955), (4, 0.010254277037139435), (5, 0.003205037218056633), (6, 0.007512579061520536), (7, 0.0007182907692681364), (8, 0.0012199950227529148), (9, -0.0043872199061536134)]\n",
      "[(0, 0.0263524443272887), (1, 0.0071964231167035795), (2, -0.0016039044408344867), (3, 0.00456722852921116), (4, 0.0034914169307697406), (5, -0.01016869765142659), (6, -0.0021337653886918167), (7, -0.006471794961194971), (8, 0.0008302112498956094), (9, -0.01670786188977747)]\n",
      "[(0, 0.2646618820986156), (1, 0.22642697512240811), (2, 0.10993306476517442), (3, -0.160897225990557), (4, 0.025250867217003526), (5, 0.028243355276995355), (6, 0.20741966185697386), (7, -0.02949998892685653), (8, 0.016054344303601472), (9, -0.06561837575565715)]\n",
      "[(0, 0.13506079008785435), (1, 0.11689263323014258), (2, 0.03135893761009317), (3, 0.04783203004872515), (4, -0.1163914684726105), (5, 0.047199073578219036), (6, -0.04648518228498797), (7, 0.009896077585003226), (8, 0.0711355956664273), (9, 0.11365119645243084)]\n",
      "[(0, 0.028547855193697402), (1, 0.008014135500881635), (2, 0.008622257721764327), (3, -0.0013296768709864766), (4, 0.0060148300910966585), (5, -0.0035676673029048063), (6, -0.0074533182383879435), (7, -0.004475103640403173), (8, 0.0012974665485321472), (9, -0.014126891158996735)]\n"
     ]
    }
   ],
   "source": [
    "for scores in corpus_lsi[:5]:\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use these scores to fetch best-fit classifications for all of our (classifiable) patents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = [np.argmax(np.asarray(corpus_lsi[i])[:,1]) for i in range(len(stemmed_title_common_words_nonnull))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.DataFrame({'topic': classifications, 'title': classifiable_titles})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain topics that our classifier arrives at are much more common than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    260622\n",
       "1     42014\n",
       "3     24496\n",
       "4     13912\n",
       "9     10527\n",
       "8      8873\n",
       "6      8659\n",
       "7       577\n",
       "2       395\n",
       "5       347\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our classes look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[Method, Of, Treating, Intraoccular, Tissue, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[Method, And, Apparatus, For, Providing, An, E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[Computer-Implemented, Method, ,, System, And,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[Selecting, Graphical, Component, Types, At, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>[Removal, Of, High, Molecular, Weight, Aggrega...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic                                              title\n",
       "1      0  [Method, Of, Treating, Intraoccular, Tissue, P...\n",
       "2      0  [Method, And, Apparatus, For, Providing, An, E...\n",
       "3      0  [Computer-Implemented, Method, ,, System, And,...\n",
       "4      0  [Selecting, Graphical, Component, Types, At, R...\n",
       "5      0  [Removal, Of, High, Molecular, Weight, Aggrega..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Relevance, Sorting, For, Database, Searches]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>[Implicit, Searching, For, Mobile, Content]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>[Call, Control, Server]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "      <td>[Receiver, For, A, Differential, Data, Bus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>[Data, Rate, Acquisition, Using, Signal, Edges]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic                                            title\n",
       "0       1    [Relevance, Sorting, For, Database, Searches]\n",
       "19      1      [Implicit, Searching, For, Mobile, Content]\n",
       "53      1                          [Call, Control, Server]\n",
       "77      1      [Receiver, For, A, Differential, Data, Bus]\n",
       "81      1  [Data, Rate, Acquisition, Using, Signal, Edges]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>2</td>\n",
       "      <td>[Imported, Lng, Treatment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>2</td>\n",
       "      <td>[Beverage, Capsule]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8962</th>\n",
       "      <td>2</td>\n",
       "      <td>[Headphones]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10974</th>\n",
       "      <td>2</td>\n",
       "      <td>[Drag-Type, Casing, Mill/Drill, Bit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11254</th>\n",
       "      <td>2</td>\n",
       "      <td>[Drag-Type, Casing, Mill/Drill, Bit]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic                                 title\n",
       "1804       2            [Imported, Lng, Treatment]\n",
       "3541       2                   [Beverage, Capsule]\n",
       "8962       2                          [Headphones]\n",
       "10974      2  [Drag-Type, Casing, Mill/Drill, Bit]\n",
       "11254      2  [Drag-Type, Casing, Mill/Drill, Bit]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>3</td>\n",
       "      <td>[Driver, For, Non-Linear, Displays, Comprising...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3</td>\n",
       "      <td>[Erasable, And, Programmable, Non-Volatile, Cell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>3</td>\n",
       "      <td>[Method, And, System, For, Accelerated, Access...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>3</td>\n",
       "      <td>[Two-Dimensional, Data, Memory]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>3</td>\n",
       "      <td>[Error, Correction, Scheme, For, Use, In, Flas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic                                              title\n",
       "178      3  [Driver, For, Non-Linear, Displays, Comprising...\n",
       "198      3  [Erasable, And, Programmable, Non-Volatile, Cell]\n",
       "232      3  [Method, And, System, For, Accelerated, Access...\n",
       "256      3                    [Two-Dimensional, Data, Memory]\n",
       "322      3  [Error, Correction, Scheme, For, Use, In, Flas..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>[Resource, Consumption, Reduction, Via, Meetin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4</td>\n",
       "      <td>[Power, Converter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>4</td>\n",
       "      <td>[Antenna, Configuration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>4</td>\n",
       "      <td>[Data, Carrier, For, Storing, Information, Rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>4</td>\n",
       "      <td>[Digital, Rights, Management, Unit, For, A, Di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic                                              title\n",
       "40       4  [Resource, Consumption, Reduction, Via, Meetin...\n",
       "74       4                                 [Power, Converter]\n",
       "157      4                           [Antenna, Configuration]\n",
       "291      4  [Data, Carrier, For, Storing, Information, Rep...\n",
       "320      4  [Digital, Rights, Management, Unit, For, A, Di..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>5</td>\n",
       "      <td>[Method, Of, Calling, Up, Object-Specific, Inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>5</td>\n",
       "      <td>[Collecting, Information, Before, A, Call]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>5</td>\n",
       "      <td>[Collecting, Information, Before, A, Call]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>5</td>\n",
       "      <td>[Collecting, Information, Before, A, Call]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3963</th>\n",
       "      <td>5</td>\n",
       "      <td>[Telephony, Usage, Derived, Presence, Informat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title\n",
       "285       5  [Method, Of, Calling, Up, Object-Specific, Inf...\n",
       "2050      5         [Collecting, Information, Before, A, Call]\n",
       "2557      5         [Collecting, Information, Before, A, Call]\n",
       "3357      5         [Collecting, Information, Before, A, Call]\n",
       "3963      5  [Telephony, Usage, Derived, Presence, Informat..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[Communication, Station, For, Communication, W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>[Mobile, Search, Substring, Query, Completion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>[Creation, Of, A, Mobile, Search, Suggestion, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>[Mobile, Pay-Per-Call, Campaign, Creation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>[Mobile, Pay-Per-Call, Campaign, Creation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic                                              title\n",
       "6       6  [Communication, Station, For, Communication, W...\n",
       "18      6     [Mobile, Search, Substring, Query, Completion]\n",
       "20      6  [Creation, Of, A, Mobile, Search, Suggestion, ...\n",
       "21      6         [Mobile, Pay-Per-Call, Campaign, Creation]\n",
       "22      6         [Mobile, Pay-Per-Call, Campaign, Creation]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>7</td>\n",
       "      <td>[Handling, Complex, Regex, Patterns, Storage-E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4077</th>\n",
       "      <td>7</td>\n",
       "      <td>[Generic, Information, Element]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>7</td>\n",
       "      <td>[Buddy, Lists, For, Information, Vehicles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>7</td>\n",
       "      <td>[Paper, Sheet, Handling, Apparatus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9900</th>\n",
       "      <td>7</td>\n",
       "      <td>[Setting, User-Preference, Information, On, Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title\n",
       "1465      7  [Handling, Complex, Regex, Patterns, Storage-E...\n",
       "4077      7                    [Generic, Information, Element]\n",
       "4809      7         [Buddy, Lists, For, Information, Vehicles]\n",
       "5255      7                [Paper, Sheet, Handling, Apparatus]\n",
       "9900      7  [Setting, User-Preference, Information, On, Th..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>8</td>\n",
       "      <td>[Trench, Mos, Structure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>8</td>\n",
       "      <td>[Connector, For, Chip-Card]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>8</td>\n",
       "      <td>[Multitrack, Optical, Disc, Reader]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>8</td>\n",
       "      <td>[Planarising, Damascene, Structures]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>8</td>\n",
       "      <td>[Coil, Construction]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                 title\n",
       "580       8              [Trench, Mos, Structure]\n",
       "618       8           [Connector, For, Chip-Card]\n",
       "717       8   [Multitrack, Optical, Disc, Reader]\n",
       "909       8  [Planarising, Damascene, Structures]\n",
       "1213      8                  [Coil, Construction]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9</td>\n",
       "      <td>[Mobile, Search, Result, Clustering]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9</td>\n",
       "      <td>[Mobile, Search, Service, Discovery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9</td>\n",
       "      <td>[Physical, Navigation, Of, A, Mobile, Search, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>9</td>\n",
       "      <td>[Methods, ,, Systems, ,, And, Computer, Progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>9</td>\n",
       "      <td>[Wireless, Terminal, ,, Wireless, Module, And,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic                                              title\n",
       "26      9               [Mobile, Search, Result, Clustering]\n",
       "27      9               [Mobile, Search, Service, Discovery]\n",
       "30      9  [Physical, Navigation, Of, A, Mobile, Search, ...\n",
       "41      9  [Methods, ,, Systems, ,, And, Computer, Progra...\n",
       "88      9  [Wireless, Terminal, ,, Wireless, Module, And,..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Topic\", i + 1)\n",
    "    display(topics.query('topic == @i').head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
